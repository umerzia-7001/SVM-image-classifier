{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linearly separable classes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages')\n",
    "!pip3 install numpy\n",
    "!pip3 install matplotlib\n",
    "!pip3 install seaborn\n",
    "!pip3 install sklearn\n",
    "import sklearn\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns;sns.set()\n",
    "% matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets.samples_generator import make_blobs\n",
    "\n",
    "X,y=make_blobs(n_samples=50,centers=2,random_state=0,cluster_std=0.60)\n",
    "plt.scatter(X[:,0],X[:,1],c=y,s=50,cmap='summer')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The linear classifiers we know will draw a straight line between the classes. With this example, we could do this by hand. But what should strike you is that there is more than one decision boundary (lines) that can achieve minimum in-sample error.  Let's plot them below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting the margins:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xfit=np.linspace(-1,3.5)\n",
    "plt.scatter(X[:,0],X[:,1],c=y,s=50,cmap='summer')\n",
    "for m,b,d in [(1,0.65,0.33),(0.5,1.6,0.55),(-0.2,2.9,0.2)]:\n",
    "    yfit=m*xfit +b \n",
    "    plt.plot(xfit,yfit,'-k')\n",
    "    plt.fill_between(xfit,yfit-d,yfit+d,edgecolor='none',color='#AAAAAA',alpha=0.4)\n",
    "plt.xlim(-1,3.5); "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When using SVMs, the decision boundary that maximizes this *margin* is chosen as the optimal model. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVM in practice:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the data from before, let us now train an SVM model with Scikit-Learn's suppport vector classifier. We'll defer the discussion about kernels for later in the course. For the time being, we will use a `linear` kernel and set the `C` parameter to an arbitrarily large number."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC \n",
    "model=SVC(kernel='linear',C=1E10)\n",
    "model.fit(X,y)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualizing the SVM decision boundaries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_svc_decision_function(model, ax=None, plot_support=True):\n",
    "    \"\"\"Plot the decision function for a 2D SVC\"\"\"\n",
    "    if ax is None:\n",
    "        ax = plt.gca()\n",
    "    xlim = ax.get_xlim()\n",
    "    ylim = ax.get_ylim()\n",
    "    \n",
    "    # create grid to evaluate model\n",
    "    x = np.linspace(xlim[0], xlim[1], 30)\n",
    "    y = np.linspace(ylim[0], ylim[1], 30)\n",
    "    Y, X = np.meshgrid(y, x)\n",
    "    xy = np.vstack([X.ravel(), Y.ravel()]).T\n",
    "    P = model.decision_function(xy).reshape(X.shape)\n",
    "    \n",
    "    # plot decision boundary and margins\n",
    "    ax.contour(X, Y, P, colors='k',\n",
    "               levels=[-1, 0, 1], alpha=0.5,\n",
    "               linestyles=['--', '-', '--'])\n",
    "    \n",
    "    # plot support vectors\n",
    "    if plot_support:\n",
    "        ax.scatter(model.support_vectors_[:, 0],\n",
    "                   model.support_vectors_[:, 1],\n",
    "                   s=300, linewidth=1, facecolors='none');\n",
    "    ax.set_xlim(xlim)\n",
    "    ax.set_ylim(ylim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(X[:,0],X[:,1],c=y,s=50,cmap='summer')\n",
    "plot_svc_decision_function(model);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The bold line dividing the data maximizes the margin between the two sets of points. Count the number of training points just touching the margin. These three points are known as the *support vectors*. These points exactly satisfying the margin are stored in the `support_vectors_` attribute of the classifier in Scikit-Learn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.support_vectors_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FACE RECOGNITION \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.datasets import fetch_lfw_people\n",
    "faces=fetch_lfw_people(min_faces_per_person=60)\n",
    "print(faces.target_names)\n",
    "print(faces.images.shape)\n",
    "\n",
    "fig,ax=plt.subplots(3,5)\n",
    "for i,axi in enumerate(ax.flat):\n",
    "    axi.imshow(faces.images[i],cmap='bone')\n",
    "    axi.set(xticks=[],yticks=[],xlabel=faces.target_names[faces.target])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC \n",
    "from sklearn.decomposition import RandomizedPCA\n",
    "from sklearn.pipeline import make_pipeline \n",
    "pca=RandomizedPCA(n_components=150,whiten=True,random_state=42)\n",
    "svc=SVC(kernel='rbf',class_weight='balanced')\n",
    "model=make_pipeline(pca,svc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cross_validation import train_test_split\n",
    "Xtrain,Xtest,ytrain,ytest=train_test_split(faces.data,faces.target,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.grid_search import GridSearchCV\n",
    "\n",
    "param_grid={'svc__C':[1,5,10,50],'svc__gamma':[0.0001,0.0005,0.001,0.005]}\n",
    "grid=GridSearchCV(model,param_grid)\n",
    "%time grid.fit(Xtrain,ytrain)\n",
    "print(grid.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=grid.best_estimator_\n",
    "yfit=model.predict(Xtest)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax=plt.subplots(4,6)\n",
    "for i,axi in enumerate(ax.flat):\n",
    "    axi.imshow(Xtest[i].reshape(62,47),cmap='bone')\n",
    "    axi.set(xticks=[],yticks=[])\n",
    "    axi.set_ylabel(faces.target_names[yfit[i]].split()[-1],color='black' if \n",
    "                   yfit[i]==ytest[i] else 'red')\n",
    "fig.suptitle('predicted Names; Incorrect Lables in Red',size=14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(ytest,yfit,target_names=faces.target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "mat=confusion_matrix(ytest,yfit)\n",
    "sns.heatmap(mat.T,square=True,annot=True,fmt='d',\n",
    "           cbar=False,xticklabels=faces.target_names,yticklabels=faces.target_names)\n",
    "plt.xlabel('True label')\n",
    "plt.ylabel('Predicted label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
